{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfreZapIVnKlI0f8U5VqbL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GNANASAMBANTHAN/GNANASAMBANTHAN/blob/main/Mini_Project_6_Ebola_Data_Analytics_%2B_Linear_Regression_House_Prediction_ML_Task_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Questions***   \n",
        "***Part I***      \n",
        "1. Distinct # of Indicators in the universe (complete dataset).\n",
        "2. In the second half of the year 2015, how many countries have one or more “Cumulative number of confirmed Ebola cases”\n",
        "3. Top 10 total Ebola cases confirmed. Note that Indicator = Cumulative number of confirmed Ebola cases. Include rank based on the total value (=cases confirmed).\n",
        "4. Top 10 countries that have total cases with Indicator = “Cumulative number of confirmed probable and suspected Ebola deaths” in 2015 Q2 (i.e., April-June 2015).\n",
        "5. Top 10 countries that have total cases with Indicator = “Cumulative number of confirmed probable and suspected Ebola deaths” with only even months of the year 2015 (i.e., months 2, 4, 6, 8, 10, 12).\n",
        "6. Find Country and Indicator wise total value. Also, rank on the total_value which is the sum at the Country-Indicator level.\n",
        "7. For those Top 10 countries by Indicator = Cumulative number of confirmed Ebola cases, plot group bar chart.\n",
        "***Part II***     \n",
        "1. Read \"song.csv\" into a dataframe and then produce the following output.\n",
        "Write Output For Ranked Songs By its Highest Frequency. Whichever song won a particular rank (say 2) with maximum frequency takes that place. For example, Mysong1 won rank 1 for two different years (achieved maximum frequency for that particular rank) and so in output (see row 1 in Output expected below), it should appear as Mysong1 with rank 1 and count 2..\n",
        "(Note. in the same year, now two songs have same rank.)           \n",
        "2. House Price Prediction task.\n",
        "    1. Pre-processing: Convert non-numeric columns (mainroad, guestroom, basement, hotwaterheating, airconditioning) to numeric using one-hot encoding if the column values are not interrelated. If column values are related, need to use ordinal encoding.\n",
        "    2. Pre-processing: Use pd.get_dummies to convert the one-hot encoding from the previous step into single columns. [link | link]\n",
        "    3. Use two-fold cross-validation [sklearn]  and predict (use linear regression) the house price (column \"price\") using features (all columns except \"price\" are the features). You need output evaluation metrics: R1-squared error, Mean Squared Error (MSE), Root Mean Squared Error (RMSE). Mean Average Error (MAE). See doc for some short introduction for these evaluation metrics. In case the evaluation metrics (RMSE, MAE, MSE etc) have higher value (i.e., high error), then use standard scaler on the target column (column \"price\") to scale them. Additionally, you can also use standard scaler to scale the numeric features (i.e., those features other than target \"price\" and columns not converted to numeric using some encoding methods such as ordinal encoding and one-hot encoding). Some sample basic code notebook for Linear Regression (also use the internet for more) that starts with import of LinearRegression from sklearn.linear_model.\n",
        "3. Create three equal-size buckets of House Price data. Bin the data into 3 quantiles (new column: quantile) of  'low', 'medium', 'high' based on \"price\" column in the House Price dataset.\n"
      ],
      "metadata": {
        "id": "pPjYA_HOiOae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ437dVXgBCV"
      },
      "outputs": [],
      "source": []
    }
  ]
}